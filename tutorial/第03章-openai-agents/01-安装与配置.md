这个框架是OpenAI在2025年3月份刚刚推出的，与MCP进行了比较好的融合。
框架默认是用opanai的大模型，我们可以改成用deepseek的模型。实际上这个框架国内模型只支持deepseek。

如果我们要用国内的大模型，那么安装的时候就不能用它的默认安装了，需要一点小小的改动。

第一步：起一个虚拟环境。养成好习惯，尝试新技术，都用虚拟环境去尝试。
```bash
python -m venv openai-agent

# 如果是mac或者linux系统，激活虚拟环境：
source openai-agent/bin/activate

# 如果是windows系统，在cmd黑窗口激活虚拟环境：
openai-agent\Scripts\activate

# 如果是Windows系统下的vs code或cursor的终端，输入这行进入虚拟环境：
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass; .\openai-agent\Scripts\Activate.ps1
```




第二步：安装依赖。
```bash
pip install "openai-agents[litellm]"
```
这里要稍微介绍一下，`openai-agents[litellm]`是安装OpenAI Agent框架的命令。这里的`litellm`是一个可选依赖，它允许你使用任何支持Litellm API的大模型服务（例如DeepSeek、Hugging Face等），而不仅仅是OpenAI的服务。

上面这行pip命令会自动安装`litellm`库。安装完后，我们先来测试一下如何使用`litellm`来配置DeepSeek或其他模型。

```python
from litellm import completion

response = completion(
    model="ollama/qwen2.5:7b", 
    messages=[{ "content": "你有什么技能？","role": "user"}], 
    api_base="http://192.168.0.123:11434"
)
print(response.choices[0].message.content)
```
我能够帮助您生成各种类型的文本，如文章、故事、诗歌、故事等；我可以提供各种语言的翻译服务；我能回答各种问题和查询，包括但不限于科技、文化、教育等领域的问题；我还能够模拟不同的对话场景，比如客服、面试等；此外，我还可以辅助进行一些简单的数据分析和处理。如果您有任何具体需求或想要探讨的话题，请随时告诉我！


## 接入deepseek模型
如果要配置deepseek模型，我们需要一个api_key，你可以在deepseek的官方网站注册账号并获取。然后在你的代码中来加载环境变量。api_key要好好保密，不要泄露出去。免得被人盗用，让余额用光光。

在项目的根目录新建一个txt文件，把文件名改成.env。需要注意的是，前面这个点儿不能省略。因为这个文件就叫做dotenv，dot就是点儿的意思。
里面填入一行字符串：
DEEPSEEK_API_KEY=sk-14f72d43388wa3e711a544t2f5960eb0

把DEEPSEEK_API_KEY写到.env文件的原因是为了保密，同时可以方便地在不同的代码中读取。

安装dotenv库，以便在Python代码中读取.env文件中的环境变量：

```bash
pip install python-dotenv
```
然后，在你的Python代码中加载这个环境变量：

```python
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('DEEPSEEK_API_KEY')
base_url = "https://api.deepseek.com/v1"
chat_model = "deepseek/deepseek-chat"
```

再次运行，

```python
from litellm import completion

response = completion(
    model=chat_model, 
    messages=[{ "content": "你有什么技能？","role": "user"}], 
    api_base=base_url,
    api_key=api_key
)
print(response.choices[0].message.content)
```

输出以下信息：
```markdown
作为一个人工智能助手，我拥有多种技能，可以帮助你处理各种任务！以下是我的一些核心能力：  

### 📚 **知识问答**  
- 提供科学、历史、技术、文化等领域的知识。  
- 解释复杂概念（如量子力学、经济学等）。  
- 实时查询最新信息（需联网）。  

### ✍️ **写作与创作**  
- 撰写文章、报告、论文大纲、商业计划书等。  
- 生成故事、诗歌、广告文案、社交媒体帖子。  
- 帮助润色、改写或优化文本。  

### 📊 **学习与工作辅助**  
- 代码编写与调试（Python、Java、SQL等）。  
- 数学计算、数据分析、公式推导。  
- 制作简历、求职信、PPT大纲。  

### 🌍 **语言翻译与学习**  
- 多语言翻译（中英、法、德、日、西等）。  
- 语法检查、单词解释、语言学习建议。  

### 🤖 **AI 与技术**  
- 解释机器学习、深度学习、AI 相关概念。  
- 提供编程示例（如爬虫、自动化脚本）。  
...
- 支持文件上传（PDF/Word/Excel等），提取并分析内容。  
- 联网搜索最新信息（需用户开启）。  

如果你有任何具体需求，可以直接告诉我，我会尽力帮你高效解决！ 😊
```


我们再继续搭建OpenAI Agent框架。

```python
from agents import Agent, Runner, set_tracing_disabled
from agents.extensions.models.litellm_model import LitellmModel
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)
agent = Agent(name="Assistant", model=llm, instructions="You are a helpful assistant")
result = Runner.run_sync(agent, "给我讲个程序员相亲的笑话")
print(result.final_output)
```

上面这段代码是不能在jupyter notebook中运行的，因为jupyter notebook不支持asyncio。会报错：
RuntimeError: This event loop is already running

要想在jupyter notebook中运行，需要做一些小小的改动

result = Runner.run_sync(agent, "给我讲个程序员相亲的笑话")
改成
result = await Runner.run(agent, "给我讲个程序员相亲的笑话")

就可以了。

建立try.py文件，终端运行 python try.py,输出：
```markdown
程序员小王去相亲，女生问他：“你是做什么工作的？”

小王：“我是程序员，专门写代码的。”

女生点点头：“哦……那你们是不是经常加班啊？”

小王认真回答：“其实我们用的是**敏捷开发**，加班不是常态，除非遇到**死线（Deadline）**。”

女生又问：“那你平时有什么爱好吗？”

小王：“我喜欢**重构代码**，偶尔**debug到凌晨**，周末爱逛**GitHub**和**Stack Overflow**。”

女生尴尬一笑：“……你谈过几次恋爱？”

小王想了想：“零次。不过如果恋爱像写代码，我现在应该算在**长期维护一个开源项目**，只是还没找到**合适的贡献者**。”

女生忍不住问：“你觉得我怎么样？”

小王盯着她看了三秒：“你的**兼容性**很好，但我们需要先跑个**单元测试**，再考虑是否**合并到主分支**。”

女生：“……再见。”

小王自言自语：“咦？怎么又**连接超时**了……”

---

（程序员：不是我不浪漫，是你们不懂我的**语法糖**😂）
```

好啦，至此我们已经成功搭建了OpenAI Agent框架，并用DeepSeek模型代替了原来的OpenAI模型。

## 接入Azure模型

```python
from agents import Agent, Runner, set_tracing_disabled
from agents.extensions.models.litellm_model import LitellmModel
import os
from dotenv import load_dotenv

# 加载环境变量
load_dotenv()
# 从环境变量中读取api_key
api_key = os.getenv('azure_key')
base_url = os.getenv('azure_endpoint')
chat_model = "azure/gpt-4o" # 这里的gpt-4o是deployment的名称
set_tracing_disabled(disabled=True)
llm = LitellmModel(model=chat_model, api_key=api_key, base_url=base_url)
agent = Agent(name="Assistant", model=llm, instructions="You are a helpful assistant")
result = Runner.run_sync(agent, "给我讲个程序员相亲的笑话")
print(result.final_output)
```

输出结果也和上面的笑话类似。
